// ///fold:


// // helper function
var exp = function(x){return Math.exp(x)}

// // helper function
var marginalize = function(dist, key){
  return Infer({model: function(){sample(dist)[key]}})
}

// // for discretization

var binParam = 5;

var round = function(x){
  return Math.round(x*10)/10
}

// introduce parameters for three possible subordinate and a basic category
var stateParams = {
  dog1: {mu: 1, sigma: 0.5},
  dog2: {mu: 0, sigma: 0.5},
  dog3: {mu: -1, sigma: 0.5},
  super: {mu: 0, sigma: 1}
};

// rangle of possible sizes
var stateVals = map(
  round,
  _.range(stateParams.super.mu - 2 * stateParams.super.sigma,
          stateParams.super.mu + 2 * stateParams.super.sigma + stateParams.super.sigma/binParam,
          stateParams.super.sigma/binParam)
);

// probabilitites of possible sizes depending on cc
var stateProbs = function(cc) {
  return map(function(s){
    Math.exp(Gaussian(stateParams[cc]).score(s))+
    Number.EPSILON
  }, stateVals)
};

// generate the uniform threshold prior
var thresholdBins = function(form, stateSupport){
  return map(function(x){
    return form == "positive" ? x - (1/(binParam*2)) : x + (1/(binParam*2));
  }, sort(stateSupport))
}

var thresholdPrior = function(form, stateSupport){
  return Infer({
    model: function() { return uniformDraw(thresholdBins(form, stateSupport)) }
  });
};


var statePrior = function(cc) {
  Infer({
//    method: 'MCMC',
    model: function() {
    return categorical({vs: stateVals, ps: stateProbs(cc)})

   }
  })
};


var context = {
  // basic-level context, with a 2 members from three different subordinate categories
  super: [ {referent: "dog1", property: 1},
         {referent: "dog1", property: 1.6},
         {referent: "dog2", property: 0},
         {referent: "dog2", property: 0.2},
         {referent: "dog3", property: -1},
         {referent: "dog3", property: -1}
  ],
  sub: [ {referent: "dog1", property: 1},
         {referent: "dog1", property: 1},
         {referent: "dog1", property: 1},
         {referent: "dog1", property: 1},
         {referent: "dog1", property: 1},
         {referent: "dog1", property: 1}
  ]
}

// possible statePrior parameters are adjusted to represent three different subordinate categories (above)

// additionally to the context representation, there is a variable whether the target referent
// is already accommodated or not, i.e. if reference is established or not

/////////////////////////////
// functions for the L1

// the L1 is going to infer if reference is established or not;
// however this might be not entirely plausible given our experimental setup

// S1 knows its value, L0 gets it
var establishRef = Infer({
  model: function(){return uniformDraw([true, false])}
});

// referent prior given (known) context
var targetPrior = function(context){ // gets the respective list, for L1
  Infer({
    model: function(){return uniformDraw(context)}
  });
}

// assume a uniform prior over comparison classes
var classPrior = Infer({
  model: function(){return uniformDraw(["sub", "super"])}
});
/////////////////////////


// prior N position distribution (uniform)
var Nposition = function(){
  Infer({ // think if Infer is necessary here
    model: function(){return uniformDraw(['subj', 'pred'])}
  })
}

// now meaning of the referential utterance depends on establishRef:
// if T: state matches the target that L0 gets from S1.
// if F: state (i e the referent) needs to be sampled from the context
// this allows to have a generic meaning representation of all the utterances,
// and their utility depends on the state space restriction provided by establishRef
// "that", "dog" true of any referent, "sub" true if matching the category

// there are two meaning functions, for each L0 respectively

//////////////////////
// now the meaning function has the flip() calls, since otherwise it might happen that there is no possible utterance
// for a given target (i.e. when reference is true and state == target (e.g. 'dog2'), and the utterance is e.g. 'dog1')
/////////////////////

// only 1 N can occur in the utterance, its position Npos is randomly sampled by S1
// only the felicitous sub noun should be used
var utterance = function(form, Npos, referent) {
  var subject = Npos == "subj" ? uniformDraw([referent, "dog"]) : "that";
  var predicate = Npos == "pred" ?
      form == "positive" ?
      uniformDraw(["big "+ referent, "big dog"]) :
  uniformDraw(["small "+ referent, "small dog"]):
                                  form == "positive" ? "big" : "small";
  return {subject, predicate}
}

var jointMeaning = function(utterance, splitPred, state, estabishRef, threshold) {
  var refTruthVal = utterance.subject == 'that' ? true : utterance.subject == "dog" ? true : utterance.subject == state.referent ? flip(0.999) : flip(0.001);
  var predTruthVal = splitPred == "big" ? state.property > threshold ? flip(0.999) : flip(0.001) :
                                      state.property < threshold ? flip(0.999) : flip(0.001)
  return refTruthVal && predTruthVal
}

var jointL0 = function(utterance, context, establishRef, target, cc, threshold, subordinate) {
  Infer({
    method: "enumerate",
    model: function(){
      var splitPred = utterance["predicate"].split(" ");
      var explicitCC = splitPred.length == 1 ? cc : splitPred[1];
   // get the category of the CC
      var c = explicitCC == "dog" ?  "super" :
               explicitCC == "sub" ? target.referent : explicitCC
      var state = {
        referent: establishRef == true ? target.referent : uniformDraw(context)["referent"],
        property: sample(statePrior(c))
      }
      var m = jointMeaning(utterance, splitPred[0], state, establishRef, threshold)
      condition(m)
      return {referent: state.referent, property: state.property, CC: c}
    }
  })
}

// viz.marginals(jointL0({subject:"dog1", predicate: "big"}, context["super"], false, {referent: "dog1", property: 1}, "super", 0.5, "dog1"))
// viz.marginals(jointL0({subject:"dog1", predicate: "big"}, context["super"], true, {referent: "dog1", property: 1}, "super", 0.5, "dog1"))

// viz.marginals(jointL0({subject:"that", predicate: "big dog1"}, context["super"], false, {referent: "dog1", property: 1}, "super", 0.5, "dog1"))
// viz.marginals(jointL0({subject:"that", predicate: "big dog1"}, context["super"], true, {referent: "dog1", property: 1}, "super", 0.5, "dog1"))


// the speaker has a state in mind, a context, knows whether reference was established,
// knows the form of the adjective he wants to use, a threshold and has a CC in mind (for subject-N cases)
var speakerContext = cache(function(state, context, establishRef, form, threshold, cc, subordinate){
  Infer({
    method: "enumerate",
    model: function() {
      var Npos = sample(Nposition()) // sample the position of the N
      var utt = utterance(form, Npos, state.referent) // sample an utterance

      var L0 = jointL0(utt, context, establishRef, state, cc, threshold, subordinate)
      var c = cc == 'sub' ? state.referent : "super";
      var ut = L0.score({referent: state.referent, property: state.property, CC: c})
      factor(3*ut)
//       factor(0)
      return utt
    }
  })
}, 10000)

// the speaker model makes nice predictions:
// when reference = T, it prefers a N in predicate position and
// disprefers the sub N with decreasing size of the referent (plot 1 vs plot 5)
// when reference = F, it preferes a sub N in subject position given basic level context (e g plot 2 vs plot 1)
// however, as predicted in sub context there is no difference in subj N preference when reference varies:
// this is because all referring expression have equal utility in sub context

// display("Basic context, big Great Dane, reference = T")
// viz(speakerContext({referent: 'dog1', property: 1}, context['super'], true, "positive", 0.5, "super", "dog1") )
// display("Basic context, big Great Dane, reference = F")
// viz(speakerContext({referent: 'dog1', property: 1}, context['super'], false, "positive", 0.5, "super", "dog1") )
// display("Sub context, big Great Dane, reference = T")
// viz(speakerContext({referent: 'dog1', property: 1.6, name: "A"}, context['sub'], true, "positive", 0, "super") )
// display("Sub context, big Great Dane, reference = F")
// viz(speakerContext({referent: 'dog1', property: 1.6, name: "A"}, context['sub'], false, "positive", 0, "super") )
// display("CC = sub")
// display("Basic context, big Great Dane, reference = T")
// viz(speakerContext({referent: 'dog1', property: 1.6, name:"A"}, context['super'], true, "positive", 0, "dog1") )
// display("Basic context, big Great Dane, reference = F")
// viz(speakerContext({referent: 'dog1', property: 1.6, name: "A"}, context['super'], false, "positive", 0, "dog1") )
// display("Sub context, big Great Dane, reference = T")
// viz(speakerContext({referent: 'dog1', property: 1.6, name: "A"}, context['sub'], true, "positive", 0, "dog1") )
// display("Sub context, big Great Dane, reference = F")
// viz(speakerContext({referent: 'dog1', property: 1.6, name: "A"}, context['sub'], false, "positive", 0, "dog1") )


/////////////////////
// the pragmatic listener model was added
// assume that L1 samples the target from the perceptual context only, and notably has perfect access to the context (i.e. perfect knowledge of the size of the targets)
////////////////////

// the model works and makes relatively reasonable predications for some aspects: basic CC is more likely in basic than in sub context
// ref = T is more likely in predicate than in subject-N condition, but only in basic context

var pragmaticListener = function(utterance, form, cont) {
  Infer({
    method: "enumerate",
    model: function(){
    // uncertainty about the comparison class (super vs. sub)
    var c = sample(classPrior)
    var currentContext = context[cont]
    // sample target
    var target = sample(targetPrior(currentContext))
    var subordinate = target.referent
    // sample establishReference variable
    var isReference = sample(establishRef)
    var currentStatePrior = statePrior(subordinate)
    var state = {referent: target.referent, property: sample(currentStatePrior)}
    // sample threshold
    var threshold = sample(thresholdPrior(form, currentStatePrior.support() ))
    var S1 = speakerContext(state, currentContext, isReference, form, threshold, c, subordinate);
    observe(S1, {subject: utterance.subject, predicate : utterance.predicate});
    return { comparisonClass: c, referent: state.referent, property: state.property, isRef: isReference}
  }})
}

// marginals are easier to parse
// display("Subject vs predicate sub N in basic context")
viz.marginals(pragmaticListener({subject: "dog1", predicate: "big"}, "positive", "super"))
viz.marginals(pragmaticListener({subject: "that", predicate: "big dog1"}, "positive", "super"))

// display("Sub N in predicate condition in basic vs sub context")
// viz.marginals(pragmaticListener({subject: "that", predicate: "big dog1"}, "positive", "super"))
// viz.marginals(pragmaticListener({subject: "that", predicate: "big dog1"}, "positive", "sub"))

// display("Basic N in predicate vs subject position in basic context")
// viz.marginals(pragmaticListener({subject: "that", predicate: "big dog"}, "positive", "super"))
// viz.marginals(pragmaticListener({subject: "dog", predicate: "big"}, "positive", "super"))
