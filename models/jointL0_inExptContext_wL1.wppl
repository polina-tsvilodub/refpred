// ///fold:


// // helper function
var exp = function(x){return Math.exp(x)}

// // helper function
var marginalize = function(dist, key){
  return Infer({model: function(){sample(dist)[key]}})
}

// // for discretization

var binParam = 5;

var round = function(x){
  return Math.round(x*10)/10
}

// introduce parameters for three possible subordinate and a basic category
var stateParams = {
  dog1: {mu: 1, sigma: 0.5},
  dog2: {mu: 0, sigma: 0.5},
  dog3: {mu: -1, sigma: 0.5},
  super: {mu: 0, sigma: 1}
};

// rangle of possible sizes
var stateVals = map(
  round,
  _.range(stateParams.super.mu - 2 * stateParams.super.sigma,
          stateParams.super.mu + 2 * stateParams.super.sigma + stateParams.super.sigma/binParam,
          stateParams.super.sigma/binParam)
);

// probabilitites of possible sizes depending on cc
var stateProbs = cache( function(cc) {
  return map(function(s){
    Math.exp(Gaussian(stateParams[cc]).score(s))+
    Number.EPSILON
  }, stateVals)
});


/////////////////////
// inspired by dynamic semantics & discourse representation theory
// the idea is the following:
// main points made in E3 and hence to be made in the model in general:
// 1. main effect of context
// 2. (main) effect of basic vs subordinate noun choice
// 3. NP X syntax interaction in basic-context

// This means we need a context representation, which can change independently of
// (/it is a different thing than) the world knowledge, represented by the statePrior


//////////////////////////
// most important new components of this model version:
// the contexts: explicit contexts corresponding to the ones in E3
// allowing utterances with one N only
// include 'world knowledge' (i e statPrior) for 3 different sub categories
// there is one joint L0 (and one joint meaning function)

/////////////////////////////
// generate the uniform threshold prior
var thresholdBins = function(form, stateSupport){
  return map(function(x){
    return form == "positive" ? x - (1/(binParam*2)) : x + (1/(binParam*2));
  }, sort(stateSupport))
}

var thresholdPrior = function(form, stateSupport){
  return Infer({
    model: function() { return uniformDraw(thresholdBins(form, stateSupport)) }
  });
};

var statePrior = function(cc) {
  Infer({
    model: function() {
      return categorical({vs: stateVals, ps: stateProbs(cc)})
   }
  })
};


var context = {
  // basic-level context, with a 2 members from three different subordinate categories
  super: [ {referent: "dog1", property: 1, name: "A"},
         {referent: "dog1", property: 1.6, name: "B"},
         {referent: "dog2", property: 0, name: "C"},
         {referent: "dog2", property: 0.2, name: "D"},
         {referent: "dog3", property: -1, name: "E"},
         {referent: "dog3", property: -1, name: "F"}
  ],
  sub: [ {referent: "dog1", property: 1, name: "A"},
         {referent: "dog1", property: 1, name: "B"},
         {referent: "dog1", property: 1, name: "C"},
         {referent: "dog1", property: 1, name: "D"},
         {referent: "dog1", property: 1, name: "E"},
         {referent: "dog1", property: 1, name: "F"}
  ]
}
// possible statePrior parameters are adjusted to represent three different subordinate categories (above)

// additionally to the context representation, there is a variable whether the target referent
// is already accomodated or not, i.e. if reference is established or not


// referent prior
var targetPrior = function(context){ // gets the respective list, for L1
  Infer({
    model: function(){return uniformDraw(context)}
  });
}

// assume a uniform prior over comparison classes
var classPrior = Infer({
  model: function(){return uniformDraw(["sub", "super"])}
});

/////////////////////////


var Nposition = function() {
  Infer({
    model: function(){
      return uniformDraw(['subj', 'pred'])
    }
  })
}


// only 1 N can occur in the utterance, its position Npos is randomly sampled by S1
var utterance = function(form, Npos) {
  var subject = Npos == "subj" ? uniformDraw(["dog1", "dog2", "dog3",  "dog"]) : "that";
  var predicate = Npos == "pred" ? form == "positive" ? uniformDraw(["big dog1", "big dog2", "big dog3", "big dog"]) :
                                       uniformDraw(["small dog1", "small dog2", "small dog3", "small dog"]):
                                  form == "positive" ? "big" : "small";
  return {subject, predicate}
}

// joint meaning function:
// again, subject is assumed to establish reference, predicate predication
// 'that' and 'dog' are always true,  the subordinate label must be applicable for specific target (flips allow for using the subordinate context)

var jointMeaning = function(utt, state, threshold, adj) {
  var RefTruthVal = utt.subject == 'that' ? true : utt.subject == "dog" ? true : utt.subject == state.referent ? flip(0.999) : flip(0.001);
  var PredTruthVal = adj == "big" ? state.property > threshold ? flip(0.999) : flip(0.001):
                                      state.property < threshold ? flip(0.999) : flip(0.001);
  return RefTruthVal && PredTruthVal
}

// L0
// the known comparison class is assumed to be either basic or subordinate of the intended target (as passed from L1)
var jointL0 = function(utt, context, target, cc, threshold, subordinate) {
  Infer({
    model: function() {
      var splitPred = utt['predicate'].split(" ");
      var explicitCC = splitPred.length == 1 ? cc : splitPred[1];
   // get the category of the CC
      var c = explicitCC == "dog" ?  "super" :
               explicitCC == "sub" ? subordinate : explicitCC
      var state = {
        referent: uniformDraw(_.union(context, [target])).referent,
        property: sample(statePrior(c))
      }
      var m = jointMeaning(utt, state, threshold, splitPred[0])
      condition(m )
      // returning c makes sure only felicitous comparison classes can be used
      return {referent: state.referent, property: state.property, c: c}
    }
  })
}

// viz.marginals(jointL0({subject: "that", predicate: "big dog"}, context["super"], {referent: "dog1", property: 1}, "super", 0, "dog1"))

// the speaker has a state in mind, a context,
// knows the form of the adjective he wants to use, a threshold and has a CC in mind (for subject-N cases)
var speakerContext = function(state, context, form, threshold, cc, subordinate){
  Infer({
    model: function() {
      var Npos = sample(Nposition())
      var utt = utterance(form, Npos) // sample an utterance
      // get appropriate subordinate CC
      var cc2assign = cc == 'sub' ? subordinate : "super";
      var jL0 = jointL0(utt, context, state, cc, threshold, subordinate)
      var ut = jL0.score({referent: state.referent, property: state.property, c: cc2assign})
//       compute the utility
      factor(3*ut)
      return utt
    }
  })
}

// viz(speakerContext({referent: 'dog1', property: 1, name:"A"}, context['sub'], "pred", "positive", -2.1, "sub", "dog1") )
// viz(speakerContext({referent: 'dog1', property: 1, name:"A"}, context['super'], "pred", "positive", -2.1, "sub", "dog1") )
// viz(speakerContext({referent: 'dog3', property: -1, name:"E"}, context['super'], "pred", "negative", 0, "sub", "dog3") )
// viz(speakerContext({referent: 'dog2', property: 1, name:"C"}, context['super'], "pred", "positive", 0, "super", "dog2") )


// for a more plausible implementation of our experimental set-up, the L1 knows
// the subordinate category of the referent
// what is unknown, is its precise size -- sampled from a state prior over the
// corresponding subordinate distribution (as in original CC model)

var pragmaticListener = function(utterance, form, cont, referent) {
  Infer({model: function(){
    // add the context as potential comparison class
    var c = uniformDraw(['sub', 'super', cont])

    var currentContext = context[cont]
    var subordinate = referent.sub;
    // L1 doesn't know the exact size of the referent
    var size = sample(statePrior(subordinate))

    var target = {referent: referent.sub, property: size}

    var currentStatePrior = statePrior(subordinate)
    var threshold = sample(thresholdPrior(form, currentStatePrior.support() ))

    var S1 = speakerContext(target, currentContext, form, threshold, c, subordinate);

    observe(S1, utterance);
    return { comparisonClass: c, state: size} //, QUD: qud}
  }})
}
// viz.marginals(pragmaticListener({subject: "dog1", predicate: "big"}, "positive", "super", {sub: "dog1"}))
// viz.marginals(pragmaticListener({subject: "that", predicate: "big dog1"}, "positive", "super", {sub: "dog1"}))
// display("small")
// viz.marginals(pragmaticListener({subject: "dog3", predicate: "small"}, "negative", "super", {sub: "dog3"}))
// viz.marginals(pragmaticListener({subject: "that", predicate: "small dog3"}, "negative", "super", {sub: "dog3"}))


// display("sub")
viz.marginals(pragmaticListener({subject: "dog1", predicate: "big"}, "positive", "sub", {sub: "dog1"}))
viz.marginals(pragmaticListener({subject: "that", predicate: "big dog1"}, "positive", "sub", {sub: "dog1"}))
