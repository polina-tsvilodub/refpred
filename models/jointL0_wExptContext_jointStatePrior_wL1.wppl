// ///fold:

// // helper function
var exp = function(x){return Math.exp(x)}

// // helper function
var marginalize = function(dist, key){
  return Infer({model: function(){sample(dist)[key]}})
}

// // for discretization

var binParam = 5;

var round = function(x){
  return Math.round(x*10)/10
}

// introduce parameters for three possible subordinate and a basic category
var stateParams = {
  dog1: {mu: 1, sigma: 0.5},
  dog2: {mu: 0, sigma: 0.5},
  dog3: {mu: -1, sigma: 0.5},
  super: {mu: 0, sigma: 1}
};

// rangle of possible sizes
var stateVals = map(
  round,
  _.range(stateParams.super.mu - 2 * stateParams.super.sigma,
          stateParams.super.mu + 2 * stateParams.super.sigma + stateParams.super.sigma/binParam,
          stateParams.super.sigma/binParam)
);

// probabilitites of possible sizes depending on cc
var stateProbs = cache( function(cc) {
  return map(function(s){
    Math.exp(Gaussian(stateParams[cc]).score(s))+
    Number.EPSILON
  }, stateVals)
});


/////////////////////
// the idea is the following:
// main points made in E3 and hence to be made in the model in general:
// 1. main effect of context on referential utility of the N
// 2. (main) effect of basic vs subordinate noun choice
// 3. NP X syntax interaction in basic-context

// This means we need a context representation, which can change independently of
// (/it is a different thing than) the world knowledge

// furthermore, the model should be a plausible representation of experimental set-up
// hence, the subordinate category of the referent is assumed to be known to the listener
// but L1 doesn't know the size of the referent and hence the comparison class (since it appears in distance)

// furthermore, subject and predicate should not be decoupled from each other

// so, NEW THINGS IN THIS MODEL are:
// L1 knows the subordinate category of the referent, and only infers its size and the comparison class
// a joint L0, opertaing on a joint state prior
// S1 conditioning on the comparison class
// adding the context comparison class to the set of potential comparison classes (leads to biasing the inferred comparison class of subject-N sentences)


// functions for L1

// assume a uniform prior over comparison classes
var classPrior = Infer({
  model: function(){return uniformDraw(["sub", "super"])}
});

// generate the uniform threshold prior
var thresholdBins = function(form, stateSupport){
  return map(function(x){
    return form == "positive" ? x - (1/(binParam*2)) : x + (1/(binParam*2));
  }, sort(stateSupport))
}

var thresholdPrior = function(form, stateSupport){
  return Infer({
    model: function() { return uniformDraw(thresholdBins(form, stateSupport)) }
  });
};

// a size prior for L1 for easier threshold generation
var sizePrior = function(cc) {
  Infer({
    model: function() {
      return categorical({vs: stateVals, ps: stateProbs(cc)})
   }
  })
};

// joint state prior: the referent is sampled from the union of the context & the target
// this allows to compute how informative an N is in order to refer to a target in the given context
// their sizes are sampled from a distribution set by the comparison class
// communicated either via the N in predicate position or as sampled by L1
var statePriorL0 = function(cc, context, target) {
  Infer({
    model: function() {
    var ref = _.union(context, [target])
    return {
      referent: categorical({vs: ref, ps: [1,1,1,1,1,1,1]})["referent"],
      // an assumption made here is that all sizes come from either the basic category
      // or the subordinate category of the target referent (as passed from L1 and known to L0)
      property: categorical({vs: stateVals, ps: stateProbs(cc)})
    }
   }
  })
};

// viz.marginals(statePrior("super", context["super"], {referent: "dog1", property: 1}) )
// viz.marginals(statePrior("dog1", context["super"], {referent: "dog1", property: 1}) )

var context = {
  // basic-level context, with a 2 members from three different subordinate categories
  super: [ {referent: "dog1", property: 1},
         {referent: "dog1", property: 1.6},
         {referent: "dog2", property: 0},
         {referent: "dog2", property: 0.2},
         {referent: "dog3", property: -1},
         {referent: "dog3", property: -1}
  ],
  sub: [ {referent: "dog1", property: 1},
         {referent: "dog1", property: 1},
         {referent: "dog1", property: 1},
         {referent: "dog1", property: 1},
         {referent: "dog1", property: 1},
         {referent: "dog1", property: 1}
  ]
}

// prior N position distribution (uniform)
var Nposition = function() {
  Infer({
    model: function(){
      return uniformDraw(['subj', 'pred'])
    }
  })
}

// only 1 N can occur in the utterance, its position Npos is randomly sampled by S1
var utterance = function(form, Npos) {
  var subject = Npos == "subj" ? uniformDraw(["dog1", "dog2", "dog3",  "dog"]) : "that";
  var predicate = Npos == "pred" ? form == "positive" ? uniformDraw(["big dog1", "big dog2", "big dog3", "big dog"]) :
                                       uniformDraw(["small dog1", "small dog2", "small dog3", "small dog"]):
                                  form == "positive" ? "big" : "small";
  return {subject, predicate}
}


// the joint meaning function computes the meaning of both the subject and the predicate
// subject: 'that' and 'dog' are again always true, their utility is controlled for by conditioning on the referent in S1
// predicate: standard adjective meaning computation
// true iff both sentence parts are true

var jointMeaning = function(utt, state, threshold, adj) {
  // assume subject contributes to reference, predicate to predication
  var RefTruthVal = utt.subject == 'that' ? true : utt.subject == "dog" ? true : utt.subject == state.referent ? flip(0.999) : flip(0.001);
  // I could not get rid of the flips() above because of the subordinate context: there, it otherwise happens that for 2 of 4 nouns there is no applicable referent
  var PredTruthVal = adj == "big" ? state.property > threshold ? flip(0.999) : flip(0.001):
                                      state.property < threshold ? flip(0.999) : flip(0.001);
  return RefTruthVal && PredTruthVal
}

// the joint L0 computes the meaning of an utterance given the utterance,
// context, the target, the comparison class, threshold and the subordinate category of the target
var jointL0 = function(utt, context, target, cc, threshold, subordinate) {
  Infer({
    model: function() {
      // assume subject contributes to reference, predicate to predication
      // check if predicate contains the comparison class
      var splitPred = utt['predicate'].split(" ");
      var explicitCC = splitPred.length == 1 ? cc : splitPred[1];
      // get the category of the CC
      var c = explicitCC == "dog" ?  "super" :
               explicitCC == "sub" ? subordinate : explicitCC // take the subordinate category of the referent L1 sees
      // sample a state
      var state = sample(statePriorL0(c, context, target))
      // get the meaning of the utterance for sampled state
      var m = jointMeaning(utt, state, threshold, splitPred[0])
      condition(m )
      return {referent: state.referent, property: state.property, c: c}
    }
  })
}

// viz.marginals(jointL0({subject: "that", predicate: "big dog"}, context["super"], {referent: "dog1", property: 1}, "super", 0, "dog1"))

// the speaker has a state in mind, a context, knpws the subordinate category of the state referent,
// knows the form of the adjective she wants to use, a threshold, has a CC in mind (for subject-N cases)
var speakerContext = function(state, context, form, threshold, cc, subordinate){
  Infer({
    model: function() {
      // sample noun position
      var Npos = sample(Nposition())
      var utt = utterance(form, Npos) // sample an utterance
      var c = cc == 'sub' ? state.referent : "super"; // convert sub comparison class to appropriate category
      var jL0 = jointL0(utt, context, state, cc, threshold, subordinate)
      // get the utility
      var ut = jL0.score({referent: state.referent, property: state.property, c: c})
//       compute utility, arbitrary set to 3
      factor(3*ut)
      return utt
    }
  })
}

// the speaker makes correct choices in terms of reference (chooses the correct N in the subject), or uses 'That'
// the choice of the predicate-N depends on the CC she has in mind: it's 'dog' for 'super'
// and the correct subordinate N for 'sub', but the probability of choosing predicate N does not depend on the actual size of the referent

// viz(speakerContext({referent: 'dog1', property: 1}, context['super'],  "positive", -2.1, "sub", "dog1") )
// viz(speakerContext({referent: 'dog1', property: 1}, context['super'],  "positive", -2.1, "super", "dog1") )
// viz(speakerContext({referent: 'dog3', property: -1}, context['super'],  "negative", 0, "sub", "dog3") )
// viz(speakerContext({referent: 'dog2', property: 1}, context['super'],  "positive", 0, "sub", "dog2") )
// display("Subordinate context, dog1")
// viz(speakerContext({referent: 'dog1', property: 1}, context['sub'], "positive", -2.1, "sub", "dog1") )



// for a more plausible implementation of our experimental set-up, the L1 knows
// the subordinate category of the referent

// what is unknown, is its precise size -- sampled from a state prior over the
// corresponding subordinate distribution (as in original CC model)
// and the specific comparison class

var pragmaticListener = function(utterance, form, cont, referent) {
  Infer({model: function(){
    // uncertainty over the comparison class
    // add the context as potential comparison class, since it is a plausibly salient available comparison class
    var c = uniformDraw(['sub', 'super', cont])
    var currentContext = context[cont]
    // get subordinate category of the referent which is assumed to be known to L1
    var subordinate = referent.referent;
    // L1 doesn't know the exact size of the referent -- but has prior knowledge
    // about sizes of the respective subordinate category
    var size = sample(sizePrior(subordinate))
    // construct state
    var target = {referent: subordinate, property: size}
    // get prior distribution over sizes in this subordinate category
    // the same happens in statePrior, but just the properties which are needed for the threshold computation are harder to get
    var currentStatePrior = sizePrior(subordinate)
    // sample threshold
    var threshold = sample(thresholdPrior(form, currentStatePrior.support() ))
    // get an utterance from S1
    var S1 = speakerContext(target, currentContext, form, threshold, c, subordinate);
    // condition on the utterance
    observe(S1, utterance);
    return { comparisonClass: c, state: size}
  }})
}

// L1 makes nice predictions:
// the comparison class corresponding to the N is more likely when it appears in the predicate
// the inferred size distribution corresponds to the inferred comparison classes (it shifts more extremely for predicate-N)
// the cc inferred from subject-N sentences is biases corresponding to the context

// display("The referent is a dog1, in basic context")
// display("L1 hears: That dog1 is big.")
// viz.marginals(pragmaticListener({subject: "dog1", predicate: "big"}, "positive", "super", {referent: "dog1"}))
// display("L1 hears: That's a big dog1.")
// viz.marginals(pragmaticListener({subject: "that", predicate: "big dog1"}, "positive", "super", {referent: "dog1"}))
// display("L1 hears: That dog is big.")
// viz.marginals(pragmaticListener({subject: "dog", predicate: "big"}, "positive", "super", {referent: "dog1"}))
// display("L1 hears: That's a big dog.")
// viz.marginals(pragmaticListener({subject: "that", predicate: "big dog"}, "positive", "super", {referent: "dog1"}))


// display("The referent is a dog1 in subordinate context")
// display("L1 hears: That dog1 is big.")
// viz.marginals(pragmaticListener({subject: "dog1", predicate: "big"}, "positive", "sub", {referent: "dog1"}))
// display("L1 hears: That's a big dog1.")
// viz.marginals(pragmaticListener({subject: "that", predicate: "big dog1"}, "positive", "sub", {referent: "dog1"}))

// display("The referent is a dog3 (small) in basic context")
viz.marginals(pragmaticListener({subject: "dog3", predicate: "small"}, "negative", "super", {referent: "dog3"}))
viz.marginals(pragmaticListener({subject: "that", predicate: "small dog3"}, "negative", "super", {referent: "dog3"}))
