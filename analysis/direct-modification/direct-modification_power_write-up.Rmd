---
title: "Direct Modification Power Analysis Write-Up"
author: "Polina Tsvilodub"
date: "8/18/2020"
output: github_document
---

This write-up summarizes results of a Bayesian power analysis for the Direct Modification refpred experiment. In this experiment, we manipulate the syntactic position of the noun directly modified by the adjective ("big Great Dane" appearing in the subject or in the predicate) in order to disentangle effects of reasoning about informational goals  on comparison class inference from effects of syntactic modification. The experiment has a 2-by-2 within-subjects  design, manipulating the syntax (subject vs predicate N) and the trial-type (critical vs filer, where fillers are trials from our CogSci Experiment 3). 

Smaller simulations based on data from last two direct modification pilots only (n = 45) which match the experimental design planned for the large-scale experiment revealed a high level of noise (large by-subject intercepts).
Therefore, this power analysis is based on pilot data from *all 6* direct-modification pilots (n = 180). The pilots differ in details like warm-up trials, but all use the same critical experimental items and critical condition (subject-N vs. predicate-N sentences: "That big Great Dane is a prize-winner" vs. "That prize-winner is a big Great Dane"). A detailed write-up of pilot results can be found under [https://github.com/polina-tsvilodub/refpred/blob/master/analysis/direct-modification/modificationXrefUt-pilot2.md](https://github.com/polina-tsvilodub/refpred/blob/master/analysis/direct-modification/modificationXrefUt-pilot2.md).

Crucially, we are interested in a credible *effect of syntax in the critical condition*.
We decided to build the power analysis assuming a maximal model including a main effects of syntax (subject vs predicate-N), trial type (critical vs. filler) and their *interaction* since this model is most appropriate given our experimental design, but we'll remain agnostic about the direction of the interaction estimate.

The power analysis proceeds as follows: 

1. The desired model to be used in final analyses is fit on pilot data (n = 180 subjects):

response-category = syntax * trial-type + (1 + syntax * trial-type || subjectID) + (1 + syntax * trial-type || item)

``` {r, include=FALSE}
library(tidyverse)
library(brms)
library(tidybayes)
library(broom)
library(knitr)

pilot_data <- read_csv("../../data/direct-modification/results_all_pilots_tidy.csv")
n_iter = 3000
pilot_data <- pilot_data %>%
  mutate(trial_dev = factor(trial_dev, levels = c("filler", "critical")),
         syntax_dev = factor(syntax_dev, levels = c("subj", "pred")))
contrasts(pilot_data$trial_dev) <- contr.sum(2)
contrasts(pilot_data$syntax_dev) <- contr.sum(2)

# fit full desired model on pilot data
pilot_model <- brm(
  response_num ~ syntax_dev * trial_dev + (1 + syntax_dev*trial_dev || workerid)
  + (1 + syntax_dev*trial_dev || target),
  data = pilot_data,
  family = "bernoulli",
  chains = 4,
  iter = n_iter,
  cores = 4,
  control = list(adapt_delta = 0.95),
  silent = T,
  refresh = 0
)
```

``` {r}
summary(pilot_model)
```

2. Then, posterior predictive samples are drawn from this fitted model, simulating a given number of subjects (increased iteratively from 50 to 600). New potential by-subject effects for the respective number are sampled from a gaussian distribution specified by the estimated group-level standard deviations and correlations of pilot data.
3. The model is re-computed on these posterior samples and the parameter of interest (i.e., the syntax coefficient in the critical condition) is extracted. The models were fit using 4 chains and 3000 iterations each. 
4. This process is repeated *400 times* for each simulated subjects-number. (for n = 50, 100 we only did 100 simulations, for n = 600 only 300)
5. The power for the given number of participants is calculated as the proportion of critical coefficients that were estimated in the predicted direction (i.e., the credible interval excludes 0) over all the simulations. 

The power analysis script can be found under: [https://github.com/polina-tsvilodub/refpred/blob/master/analysis/direct-modification/power_analysis.R](https://github.com/polina-tsvilodub/refpred/blob/master/analysis/direct-modification/power_analysis.R)

Here is the credible interval over the estimate for the effect of syntax in the critical condition over the progressing simulations, faceted by number of simulated subjects:
```{r, echo=FALSE, fig.height=15, fig.width= 8, message=FALSE, warning=FALSE}
setwd("results/sim_100")
full_data_100 <- list.files(
                    pattern = "direct_mod_power_analysis_fullData_final*"
                   ) %>%
  map_df(~read_csv(.))

setwd("../sim_400")
full_data_400 <- list.files(
                       pattern = "direct_mod_power_analysis_fullData_final*"
                       ) %>%
  map_df(~read_csv(.))
full_data_500 <- rbind(full_data_100, full_data_400) 

full_data_500 %>%
  filter(key == "syntax_critical") %>%
  group_by(n.subj) %>%
  mutate(seed = 1 : length(n.subj)) %>% 
  ungroup() %>%
  filter(seed %in% seq(1, 400, by = 5), !(n.subj %in% c(50))) %>%
  ggplot(aes(x = seed, y = mean, ymin = lower, ymax = upper)) +
  geom_hline(yintercept = c(0), color = "white") +
  geom_pointrange(fatten = 1/2) +
  labs(x = "simulation index",
       y = "critical syntax CrI") +
  ylim(-1, 4) +
  facet_wrap(~n.subj, ncol=1)
```


The results of the simulations reveal the following power for subject-numbers between 50 and 600, increasing by 50 subjects:
``` {r, echo=FALSE}
power_summary <- read_csv("results/direct_mod_power_analysis_fullData_3000iter_500sim_summary.csv")
power_summary
```

The power plotted as a function of number of simulations reveals oscillations of the power for less than 200 simulations:
``` {r, echo=FALSE}
read_csv("results/power_analysis_3000iter_running_power.csv") %>%
  mutate(n.subj = as.factor(n.subj)) %>%
  ggplot(., aes(x = n.sim, y = power_syntax, color = n.subj) ) +
  geom_point() +
  geom_line() +
  ylab("Power") +
  ylim(0.6, 1) +
  xlab("Number of simulations") +
  ggtitle("Power as a function of number of simulations")

```

Overall, we see that simulations of around 250 subjects already achieve a power of 0.8 and 300 subjects around 0.85, but for 350 subjects the power drops back to 0.8. 400 subjects or more show a more stable power > 0.8.  

#### Attrition rates in the pilots
Over the course of all 6 pilots, we recruited 207 participants and excluded 27 (13%), mostly due to failing the warm-up trials (i.e., taking more than 4 attempts to provide correct picture labels upon correction on labeling warm-up trials; 17 participants, 8%) or reporting a native language other than English. The rate of invalid responses post-exclusion (i.e., unclassifiable free-production responses) is around 1-3%. The participants were paid $1.00/participant. 