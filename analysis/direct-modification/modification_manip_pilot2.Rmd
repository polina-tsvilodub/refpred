---
title: "Modification Manipulation Pilot 2"
author: "Polina Tsvilodub"
date: "03 04 2020"
output: github_document
---
We ran a second pilot (n=36) for the NP modification manipulation
experiment. In contrast to the previous pilot, we push the perceptual
set-up of the experiment more towards the subordinate comparison class:
the target referent is perceptually slightly bigger (smaller) than the
other member of the same subordinate category in the context, thus
making the subordinate comparison class potentially more felicitous than
the basic-level comparison class. Additionally, these context-members
are presented as the instances to be labelled in the labeling warm-up
trials - hence we make sure that participants recognize them as members
of the same subordinate category as the target. The target is always
described with the subordinate label and hence its subordinate category
is clear.

Participants inferred the comparison class (via free paraphrase) from
the sentences 'That {big, small} NP is a prize-winner' or 'That
prize-winner is a {small, big} NP' (within-subject). We created nouns
like 'prize-winner' for five context items (trees, 2 x dogs, flowers,
birds).

``` {r libraries, echo=F, warnings=F}

library(tidyverse)
library(tidyboot)
library(brms)
library(lmerTest)
```

``` {r}
#d_infer <- read_csv('../data/results_32_modification-manipulation-pilot3.csv')
#d_infer1 <- d_infer %>% subset( select = -c(worker_id, hit_id, assignment_id, startDate))
#write_csv(d_infer1, '../data/results_32_modification_manipulation_pilot3.csv')

d_infer2 <- read_csv('../data/results_32_modification_manipulation_pilot2.csv')
```

5 participants were excluded for failing the warm-up task ( n=3 for the
labeling trials) or reporting a native language other than English
(n=2).

``` {r filter}
# exclude participants who report difficulties
d_infer2 %>% select(submission_id, comments, problems) %>% distinct() %>% View()

d_infer_woGlitches2 <- d_infer2 # %>% subset( !(submission_id %in% c()))

# exclude data from non-native English speakers and those where the language information is missing
d_infer_woGlitches2 %>% distinct(languages) %>% View()
d_infer_Native2 <- d_infer_woGlitches2 %>%
  filter(grepl("en", languages, ignore.case = T)) %>%
  select(submission_id, trial_name, trial_number, adj, item, target, response, botresponse,
         syntax, attempts, reference)

# participants who do not get the comparison class warmup right
d_infer_cc_warmup2 <- d_infer_Native2 %>% filter( trial_name == "comp_class_warmup") %>%
  group_by(submission_id) %>% count() %>%
  filter( n > 4 )

# exclude participants who need more than 4 attempts per warmup
d_infer_warmup2 <- d_infer_Native2 %>%
  filter( (trial_name == "warmup1") | (trial_name == "warmup2")) %>%
  group_by(submission_id) %>%
  filter(attempts > 4)

# excluding 6 participants
d_infer_filt2 <- anti_join(d_infer_Native2, d_infer_warmup2, by = c("submission_id"))
d_infer_filt2 <- anti_join(d_infer_filt2, d_infer_cc_warmup2, by = c("submission_id"))

```

The numbers of size-syntax and item-syntax combinations are relatively balanced.
``` {r}
d_infer_filt2 %>% count(syntax, adj)
```

The produced responses are categorized into basic-level and subordinate
responses. There were 3 invalid responses (the participants failed to
establish reference and produced the other noun as the comparison
class). Superordinate responses are collapsed with basic-level
responses.

``` {r categorization}
d_infer_main2 <- d_infer_filt2 %>% filter((trial_name == "custom_main_text1")|
                                          (trial_name == "custom_main_text2")) %>%

  mutate(syntax = factor(syntax)
         ) %>%
  select(submission_id, trial_number, target, item, response, syntax,
        adj)

# categorize responses
d_infer_main2 %>% distinct(response) %>% View()
# exclude invalid responses
d_infer_valid2 <- d_infer_main2 %>% subset(., !(tolower(response) %in% c( "gifts", "landmarks", "service animals"))) # 3 responses excluded
d_infer_main_responseCat2 <- d_infer_valid2 %>%
  rowwise() %>%
  mutate(  
    response_cat =
      ifelse( # do be extended dependent on responses provided
        tolower(response) %in% c("birds", "bird","dog", "dogs", "fish","flower", "flowers","trees", "tree", "big dogs", "other dogs", "animals", "plants","flowerrs", "tres"
                               ), "basic", "subordinate"),

    response_num = ifelse(response_cat == "basic", 1, 0),
    response_label = "basic",
    pilot_nr = 2
  )

```

``` {r}
d_infer_main_responseCat2 %>% count( item, syntax)
#d_infer_main_responseCat %>% count(item)
```

``` {r}
d_infer_main_responseCat2 %>% count(item, adj, syntax)
```


## Subject vs. predicate NP position plot

The proportion of inferred basic-level comparison classes is plotted by-syntax (subject vs. predicate) (n=31 participants). there seems to be no effect of syntax.
``` {r proportions plot}
# plot
bar.width = 0.8
d_infer_main_responseCat2 %>%  
  group_by(syntax) %>%
  tidyboot_mean(column = response_num) -> d_infer_main_responseCat.bs2


d_infer_main_responseCat.bs2 %>%
  ungroup() %>%
  mutate(syntax = factor(syntax, levels = c( "subject", "predicate"),
                            labels = c(  "Subject NP\n(That big NP is a prize-winner)", "Predicate NP\n(That prize-winner is a big NP)"))) %>%
  ggplot(., aes(x=syntax, y = mean, ymin = ci_lower, ymax = ci_upper)) +
  geom_col(position = position_dodge(bar.width), width = bar.width, color= 'black',
           alpha = 0.5, color = 'black', size = 0.5) +
  geom_linerange(position = position_dodge(bar.width), size = 0.5) +
  ggthemes::theme_few()+
  xlab("") +
  theme(legend.position = c(0.88, 0.84),#legend.text = element_text(size = 7),
        #legend.title = element_text(size = 7), 
        legend.key.size = unit(0.5,"line"))+
  scale_y_continuous(breaks = c(0, 0.5, 1))+
  ylab("Proportion of basic-level responses")
 # ggtitle("Experiment 3: Comparison Class Inference")+
 # facet_grid(~context)  +
  #ggsave("figs/expt3-cc-inference.pdf", width = 7.5, height = 3.5)
```

## By-item plot

We achieve more flexibility of the single items compared to the previous
design. However, some items elicit more subordinate comparison classes
in the subject then in the predicate position. Whereas the dog-item
(dogs2, including the great dane) might show this behavior because it
might be not very salient, the big tree item (redwood) and the big
flower item (sunflower) showed the predicted behavior in the previous
experiment, but not in this one.
``` {r}
d_infer_main_responseCat2 %>%  
  group_by(syntax, item, adj) %>%
  tidyboot_mean(column = response_num) -> d_infer_main_responseCat.bs.item2


d_infer_main_responseCat.bs.item2 %>%
  ungroup() %>%
  mutate(syntax = factor(syntax, levels = c( "subject", "predicate"),
                            labels = c(  "Subject NP\n(That big NP\n is a prize-winner)", 
                                         "Predicate NP\n(That prize-winner\n is a big NP)")),
         size = factor(adj, level = c("big", "small"), labels = c("big", "small"))) %>%
  ggplot(., aes(x=syntax, y = mean, ymin = ci_lower, ymax = ci_upper)) +
  geom_col(position = position_dodge(bar.width), width = bar.width, color= 'black',
           alpha = 0.5, color = 'black', size = 0.5) +
  geom_linerange(position = position_dodge(bar.width), size = 0.5) +
  ggthemes::theme_few()+
  xlab("") +
  theme(legend.position = c(0.88, 0.84),#legend.text = element_text(size = 7),
        #legend.title = element_text(size = 7), 
        legend.key.size = unit(0.5,"line"))+
  scale_y_continuous(breaks = c(0, 0.5, 1))+
  ylab("Proportion of basic-level responses") +
  ggtitle("By-item inferred Comparison Classes")+
  facet_grid(item~size)

```

## By-subject plot

Participants seem to choose a strategy (mostly basic-level labels) and
to stick to it throughout the experiment, showing low flexibility in
adjusting the comparison class. 
``` {r}
d_infer_main_responseCat2 %>%  
  group_by(syntax, submission_id) %>%
  tidyboot_mean(column = response_num) -> d_infer_main_responseCat.bs.subj2


d_infer_main_responseCat.bs.subj2 %>%
  ungroup() %>%
  mutate(syntax = factor(syntax, levels = c( "subject", "predicate"),
                            labels = c(  "Subject\n NP", 
                                         "Predicate\n NP"))) %>%
  ggplot(., aes(x=syntax, y = mean, ymin = ci_lower, ymax = ci_upper)) +
  geom_col(position = position_dodge(bar.width), width = bar.width, color= 'black',
           alpha = 0.5, color = 'black', size = 0.5) +
  geom_linerange(position = position_dodge(bar.width), size = 0.5) +
  ggthemes::theme_few()+
  xlab("") +
  theme(legend.position = c(0.88, 0.84),#legend.text = element_text(size = 7),
        #legend.title = element_text(size = 7), 
        legend.key.size = unit(0.5,"line"))+
  scale_y_continuous(breaks = c(0, 0.5, 1))+
  ylab("Proportion of basic-level responses") +
  ggtitle("By-item inferred Comparison Classes")+
  facet_wrap(~submission_id)

```

## Stats

Bayesian stats with maximal random effects: Whereas visually we observe
no effect of syntax, the Bayesian model with maximal random effects
shows a tendency towards the predicted effect.
``` {r}
# deviation coded syntax
d_infer_main_responseCat2 <- d_infer_main_responseCat2 %>%
  rowwise() %>%
  mutate(syntax_dev = ifelse(syntax == "subject", 1, -1))
#write_csv(d_infer_main_responseCat2, '../data/results_32_modification_manipulation_pilot2_tidy.csv')

d.infer.brm <- brm(response_num ~ syntax_dev + (1 + syntax_dev | submission_id ) + (1 + syntax_dev | target ),
                   data = d_infer_main_responseCat2,
                   family = "bernoulli",
                   cores = 4,
                   control = list(adapt_delta = 0.95))

summary(d.infer.brm)
```