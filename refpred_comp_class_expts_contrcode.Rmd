---
title: "Comparison class inference via syntactic cues"
author: "Polina Tsvilodub"
date: "25 09 2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE )
```

``` {r, echo=FALSE}
library(tidyboot)
library(tidyverse)
library(lmerTest)
library(brms)
```
# Hypothesis Outline

When interpreting a gradable adjective in a sentence like "That great dane is big" the listener needs to construct a felicitous comparison class for the adjective 'big' in order to infer the size of the target. For example, she might infer that the great dane is big in comparison to other dogs. 

Constructing the comparison class is an inferential problem, since the target might be conceptualized as a member of different levels of the taxonomy it belongs to.  

Syntactic cues like the position of the noun phrase in a simple copular sentence might help listeners restrict possible comparison classes upon hearing a sentence with a gradable adjective like "That great dane is big". 
We investigate this hypothesis in three experiments by manipulating the syntax of a sentence that is used to describe the size of an object: the syntax is either "That NP is big (small)" (the NP serves as subject) or "That's a big (small) NP" (the NP serves as predicate). We look at differences in comparison classes elicitation in these syntactic frames. 

__We hypothesize that NPs used as subjects contribute to reference, whereas NPs used as predicates contribute to predication. In terms of gradable adjectve use, predication is tantamount to communicating the comparison class, i. e. restricting the space of possible comparison classes to the felicitous one. Given our experimental design, the felicitous comparison class is the basic-level category of the target, such that the felicitous NP used as predicate tends to be the basic-level label of the target. In contrast, the NP used as subject restricts the comparison class less, and thus using both the basic-level and the subordinate labels of the target as this NP is felicitous.__


## Syntax Rating Experiment
The goal of the experiment was to obtain ratings of both syntactic conditions in direct comparison as descriptions of a target referent in context. The context picture - a parade of animals or a parade of plants of the same basic-level kind - was followed by a sentence providing the subordinate level label of the traget (e. g. "You see another great dane"). Below the sentence, the picture of the target appeared and participants were asked: "How well does each of the sentences describe it?". Both sentences use the same NP, differing only in NP position. The rating slider ends are labeled with 'very bad' and 'very well'.

__Between-subject:__ order of the syntactic conditions on the sliders

__Within-subject:__ NP (basic-level or subordinate level labels), target size (big or small), congruence (e. g. 'big great dane' or 'small great dane')


__Expectation:__ In the congruent condition, _given sentences with subordinate noun phrases (e. g. 'great dane'), we expect higher mean ratings of the Subject than the Predicate condition_. For example, 'That great dane is big' should be preferred over 'That is a big great dane'. Sentences with basic-level noun phrases should elicit similarly high ratings, regardless of the syntactic condition. In the incongruent condition, the subordinate predicate NP condition is expected to elicit the highest rating, since it is the only sentence felicitous to describe the target. Subject subordinate NP and both basic-level conditions are expected to elicit the lowest ratings. The overall endorsement will probably be lower than in the congruent condition.

### Mean rating in different conditions 
n = 30 (1 excluded as non-native speaker)
```{r syntax rating, echo = FALSE}
d_rating <- read_csv("./data/results_14_syntax-rating_30.csv")
d_rating_filter <- d_rating %>% filter(grepl("en", languages, ignore.case = T))
d_rating_warmup <- d_rating_filter %>% filter(trial_name == "custom_warmup")
d_rating_main <- d_rating_filter %>% filter((trial_name == "custom_slider1") | (trial_name == "custom_slider2"))

d_rating_main <- d_rating_main %>% mutate(np = factor(np, levels= c(0,1), 
                                                      labels = c("sub", "super")), 
                 sentence_order = factor(sentence_order, levels= c("0|1", "1|0"),
                                         labels = c("prenom_pred", "pred_prenom")),
                 target_size = factor(target_size, levels = c(0,1), 
                                      labels = c("big", "small")),
                 congruence = factor(congruence, levels = c(0, 1), 
                                     labels = c("congr", "incongr")))

# sort responses (due to bad recoding)
d_main_pred_prenom_pred <- d_rating_main %>% filter(sentence_order == "pred_prenom")  %>%
  select(submission_id, np, congruence, response1, target_size, trial_number, item) %>% mutate(condition = "pred")
d_main_pred_prenom_prenom <- d_rating_main %>% filter(sentence_order == "pred_prenom") %>%
  select(submission_id, np, congruence, response1 = response2, target_size, trial_number, item) %>% 
  mutate(condition = "prenom")
d_main_prenom_pred_prenom <- d_rating_main %>% filter(sentence_order == "prenom_pred") %>%
  select(submission_id, np, congruence, response1, target_size, trial_number, item) %>% mutate(condition = "prenom")
d_main_prenom_pred_pred <- d_rating_main %>% filter(sentence_order == "prenom_pred") %>%
  select(submission_id, np, congruence, response1 = response2, target_size, trial_number, item) %>% 
  mutate(condition = "pred")

# subset data frames
rating_prenom <- rbind(d_main_pred_prenom_prenom, d_main_prenom_pred_prenom)
rating_pred <- rbind(d_main_pred_prenom_pred, d_main_prenom_pred_pred)
d_rating_full <- rbind(rating_pred, rating_prenom)  %>%   
  mutate(condition = factor(condition, 
                            levels = c("pred", "prenom"), 
                            labels = c("subject", "predicate")),
         congruence = factor(congruence, levels = c("congr", "incongr"), 
                             labels = c("congruent\n ('big' great dane)", 
                                        "incongruent\n ('small' great dane)")),
         np = factor(np, levels = c("super", "sub"), 
                     labels = c("basic/superordinate", "subordinate"))) 


# plot 
bar.width = 0.8

d_rating_full %>%
  group_by(np, congruence, condition) %>% 
  tidyboot_mean(column = response1) %>% 
  ggplot(aes(x = np, y = mean, fill = condition, ymin = ci_lower, ymax = ci_upper)) +
  geom_col(position = position_dodge(bar.width), width = bar.width, alpha = 0.3, color = 'black') +
  geom_point(data = d_rating_full, 
             position = position_jitterdodge(),
             inherit.aes = F, aes(x = np, y = response1, color = condition),
             alpha = 0.25)+
  geom_linerange(position = position_dodge(bar.width))+ 
  facet_wrap(~congruence) +
  xlab("NP position") + 
  ylab("mean sentence rating") +
  ggtitle("Mean ratings by syntactic condition and congruence")
```

### Stats

Prediction: 

Basic - Subordinate (looks like this could positive, but we predict it should not be significant)
Subject - Predicate (looks like this could positive, but we predict it should not be significant)

Basic - Subordinate
x
Subject - Predicate
--> beta < 0


``` {r rating coding}
# contrast coding of the variables, creating numeric variables
# NP: 1 sub, -1 super (basic)
# congruence:1 congruent, -1 incongruent
# condition: 1 subject, -1 predicate

d_rating_full <- d_rating_full %>% mutate(np = ifelse(np == "basic/superordinate", -1, 1),
                                          congruence = 
                                            ifelse(congruence == 
                                                     "congruent\n ('big' great dane)",
                                                   1, -1),
                                          condition = ifelse(condition == "subject", 1, -1))
```

_Full linear model:_ The mean sentence rating (0 lowest rating, 100 highest rating) is regressed against the syntactic condition (subject vs predicate NP), the noun phrase (subordinate vs basic-level label), the congruence (congruent: e. g. 'big great dane' vs incongruent: e. g. 'small great dane') and their interaction. Additionally, random by-participant and by-item intercepts and random slope effects of all three predictors and their interactions by-participant and by-item are included. The random effect correlation is set to 0 to ensure model convergence.

Main congruence and condition effects as well as their interaction are significant (p < 0.001), as well as the three-way main effect interaction (p < 0.002).
```{r lmer stats 3-way}
# full data set
lm.fit.full <- glmer(response1 ~ condition * np * congruence + 
                  (1 + condition*np*congruence || submission_id) + 
                  (1 + condition*np*congruence  || item),
                  data = d_rating_full,
                  REML = F)

summary(lm.fit.full)
```

_Congruent trials linear model:_ We also fit a model on the congruent trials only, since the incongruent condition was rather a control than a critical condition. 
The mean sentence rating is regressed against the syntactic condition (subject vs predicate NP), the noun phrase (subordinate vs basic-level label) and their interaction. Additionally, random by-participant and by-item intercepts and random slope effects of syntax and noun phrase and their interaction by-participant and by-item are included. The random effect correlation is set to 0 to ensure model convergence.

Despite by-participant variance, the syntactic condition effect and the interaction of syntax and NP are significant (p < 0.001), the effect of the NP is also significant  (p < 0.05),

```{r rating lmer stats 2-way}

# congruent trials only

d_rating_full_congr <- d_rating_full %>% filter(congruence == 1)

lm.fit.congr <- glmer(response1 ~ condition * np  + 
                  (1 + condition*np || submission_id) + 
                  (1 + condition*np || item),
               data = d_rating_full_congr, 
               REML = F)

summary(lm.fit.congr)
```

### Bayesian Stats
``` {r rating bayes stats, echo=FALSE}
#b.lm.fit <- brm(response1 ~ condition * np * congruence + (1 + condition * np * congruence || submission_id) + 
# (1 + condition * np * congruence || item), data = d_rating_full)
#summary(b.lm.fit)
```


## NP Free Production Experiment 

In this experiment we want to test if speakers use different labels as noun phrases to describe the target given different syntactic frames. The participants see a basic-level context picture, below the sentence "This one is also in the parade", referring to the target. The target picture (big or small, balanced within-subject) was followed by the prompt "You say to your friend: ". Participants see either "That's a big (small) __ " (predicate NP) or "That __ is big (small)" (subject NP), blank to be filed in. The target size and adjective were always 'congruent', i. e. great danes are always described as big and chihuahuas as small.

__Between-subject:__ syntactic condition (predicate NP vs subject NP)

__Within-subject:__ target size (small or big)

__Expectation:__ We expect a higher proportion of subordinate target labels in the subject NP condition than in the predicate NP condition.

### Proportions of subordinate responses by syntactic condition

n = 120 (n = 58 prenominal syntax, n = 60 predicative syntax)
``` {r production, echo = FALSE}
d1 <- read_csv('./data/results_8_exp1-post-prereg-pred.csv')
d2 <- read_csv('./data/results_10_exp1-post-prereg-prenom.csv')
d3 <- read_csv('./data/results_8_exp1-post-prereg-pred_batch2.csv')
d4 <- read_csv('./data/results_10_exp1-post-prereg-prenom_batch2.csv')
x <- rbind(d1, d3)
y <- rbind(d2, d4)
d_prod <- rbind(x, y)

d_prod_filt <- d_prod %>% 
  filter(grepl("eng", languages, ignore.case = T)) %>%
  select(submission_id, trial_name, trial_number, size, item, botresponse, response,
         condition,  picture) %>% mutate(size=factor(size), syntax = factor(condition))

d_prod_main <- d_prod_filt %>% filter((trial_name =="main1") | (trial_name== "main2")) %>%
  select(submission_id, trial_number, response,  size, item, syntax, condition, picture)

d_prod_main_valid <- subset(d_prod_main, !(response %in% c("rose", "duck", "weed", "pigeon", "stingfish", "rat"))) 

d_prod_main_responseCat <- d_prod_main_valid %>%
  rowwise() %>%
  mutate( # categorize responses 
    response_cat =
      ifelse(
      tolower(response) %in% c("bird", "birds", "dog", "dogs", "fish","one plant",
                               "flower", "flowers", "tree", "trees", "animal", "plant"),
      "super", "sub"),
    resp_cat = ifelse(response_cat == "sub", 1, 0),
    response_label = "sub"
  )

# plot
d_prod_main_responseCat %>%
  group_by(syntax, response_label) %>%
  tidyboot_mean(column = resp_cat) %>% # calculate proportion of subordinate labels in the different conditions 
  ungroup() %>%
  mutate(syntax = factor(syntax, 
                            levels = c("prenominal", "predicative"),
                            labels= c("Predicate NP", "Subject NP"))
        ) %>% 
  ggplot(aes(x = syntax, fill = syntax,
                           y = mean, ymin = ci_lower, ymax = ci_upper)) +
  geom_col(position = position_dodge(0.8)) +
  geom_linerange(position = position_dodge(0.8)) +
  labs( y = "Proportion subordinate responses") +
  scale_y_continuous(limits = c(0, 1), breaks = c(0, 0.5, 1)) +
  ggtitle("The proportion of subordinate responses by syntactic condition")

```

### Stats
The reponse category (subordinate vs basic-level) is regressed against the syntax and random intercept and syntax effect by-participant and by-item. 
```{r data coding}
# subject NP -1, predicate NP 1
d_prod_main_responseCat <- d_prod_main_responseCat %>% mutate (syntax = ifelse(syntax == 'predicative', -1, 1) )
```

The main effect of syntax is significant (p < 0.05), despite of a big by-particiapnt variance. Collecting more data could increase the robustness of the statistical results. 
``` {r production lmer}

# fit regression model
prod.lm.fit <- glmer(resp_cat ~  syntax + (1 + syntax || submission_id) + (1 + syntax ||picture), data = d_prod_main_responseCat, family="binomial", REML = F)
summary(prod.lm.fit)
#confint(prod.lm.fit)
```


### Bayesian Stats

We calculate a Bayes Factor on the posterior subordinate response proportions being not equal using the Savage-Dickey probability density ratio. We can set principally adequate priors on the proportion parameter, since it is a bounded interval, thus making the BF interpretable. 
We set a uniform prior on the subordinate response proportion (Beta distribution with a = 1, b = 1) and an uninformative default student t-distribution prior on the random effects.
``` {r production bayes}
 # include priors on random effects
get_prior(resp_cat ~ 0 + syntax + (1 + syntax || submission_id) + (1 + syntax ||picture),
          data=d_prod_main_responseCat, family= "bernoulli")
# uniform prior 
#set random effect priors : syntax effects also between 0 and 1 
Prior <- c(set_prior("beta(1,1)", class = "b", lb = 0, ub = 1),
 set_prior("student_t(3,0,10)", class = "sd"))

b.lm.w_prior <- brm(resp_cat ~   0 + syntax + (1 + syntax || submission_id)+ 
                   (1 + syntax || picture), 
                  data = d_prod_main_responseCat, family = "bernoulli",
                  prior = Prior, sample_prior = T)

summary(b.lm.w_prior)
# nullhypothesis that proportions do not differ
h1_1 <- hypothesis(b.lm.w_prior, "0 - syntaxpredicative = 0 + syntaxprenominal") 

print(h1_1, digits = 3)
# probability of alternative hypothesis given the data 
1/h1_1$hypothesis$Evid.Ratio
```

## Comparison Class Inference Experiment

The question in this experiment is whether participants' comparison class inference is influenced by the syntactic frame. Particularly, we expect the predicate NP to restrict - i. e. explicitly provide - the felicitous comaprison class. 

Participants are asked to paraphrase a sentence in a free production task: They see a context picture (representatives of the same basic-level or subordinate kind, balanced) and are told that they and a friend see another not pictured member of the group. The friend utters a sentence (one of the two syntactic frames), after which the question "What do you think your friend meant?" is presented. The NP of the uttered sentence is either underspecified ('one') or the subordinate target label (balanced within-subject). The paraphrase template is "It is big (small) relative to other __ ", blank to be filled in. There are congruent and incongruent trials in the subordinate-level context condition. 

__Between-subjects:__ syntactic condition (subject vs predicate NP)

__Within-subjects:__ context picture (basic-level vs subordinate), NP ('one' or subordinate target label), size ('small' or 'big'), congruence (e. g. 'big great dane' or 'small great dane') in the subordinate contexts

__Expectation:__ In the underspecified NP condition ('one'), we expect the perceptual context to set the comparison class, i. e. subordinate paraphrase in subordinate contexts and basic-level paraphrase in basic-level contexts in both congruent and incongruent trials. In the subordinate NP condition, in the congruent condition ('big' with a priori big targets) we expect a syntax effect: The predicate NP syntax should elicit less basic-level paraphrases than the subject NP syntax.

### Proportion of basic-level responses by congruence and NP condition

n = 50 (n = 25 in prenominal, n = 25 in predicative condition)
Superordinate labels are collapsed with the basic labels 
```{r inference, echo = FALSE}
d1_infer <- read_csv("./data/results_12_comp-class-infer-pred.csv")
d2_infer <- read_csv("./data/results_13_comp-class-infer-prenom.csv")
d_infer <- rbind(d1_infer, d2_infer)

d_infer <- mutate(d_infer, NP = factor(ref_spec, levels= c(0, 1), 
                                       labels = c("subordinate", '"one"')), 
                  context_adj = factor(pic_spec, levels = c(0, 1, 2), 
                                       labels = c("congruent\n basic-level parade", 
                                                  "congruent\n subordinate parade",
                                                  "incongruent\n subordinate parade")))
d_infer_filt <- d_infer %>% 
  filter(grepl("en", languages, ignore.case = T))
# choose main trials 
d_infer_main <- d_infer_filt %>% filter((trial_name == "custom_main_text1")|
                                          (trial_name == "custom_main_text2")) %>%
  select(submission_id, trial_number, NP, context, context_adj, item, response, condition,
         context_picture, adj_cond, target_size)

d_infer_main_responseCat <- d_infer_main %>%
  rowwise() %>%
  mutate(  
    response_cat =
      ifelse(
        tolower(response) %in% c("birds", "dogs", "fish", "fishes", "flowers", 
                                 "flower", "large dogs", "dogs in the line",
                                 "other birds in the group", "small dogs", "trees",
                                 "tree's", "bird", "big tree"), "basic", 
        ifelse(tolower(response) %in% c("plant", "animal", "things", "weeds", "plants"),
               "super", "sub")),
    
    response_num = ifelse(response_cat == "sub", 0, 1),
    response_label = "basic"
  )

# include a context condition column
d_infer_main_responseCat <- d_infer_main_responseCat %>% rowwise() %>%
  mutate(
    context_cond = ifelse(context_adj == "congruent\n basic-level parade", "basic", "sub" )
  )

d_infer_main_responseCat$condition <- factor(d_infer_main_responseCat$condition, 
                                             levels = c("prenominal", "predicative"))
bar.width = 0.8
d_infer_main_responseCat %>%  
  group_by(response_label, NP, context_adj, condition) %>%
  tidyboot_mean(column = response_num) %>% ungroup() %>% 
  mutate(condition = factor(condition, levels = c( "predicative", "prenominal"), 
                            labels = c( "Subject", "Predicate"))) %>%
  ggplot(aes(x=condition, y = mean, fill = NP, ymin = ci_lower, ymax = ci_upper)) +
  geom_col(position = position_dodge(bar.width), width = bar.width) +
  geom_linerange(position = position_dodge(bar.width)) + 
  xlab("NP condition") +
  ylab("proportion of basic-level responses")+
  facet_grid(~context_adj)  

```

### Stats
The response category (basic collapsed with superordinate labels vs subordinate labels) is regressed against the syntactic condition (subject vs predicate NP position), NP ('one' vs subordinate label), the congruence and the context condition (basic level vs subordinagte level parade). The desired full random effect structure includes random by-participant and by-item intercepts, random slope NP, condition, context and congruence effects and their interactions by-participant and by-item. 

All the predictors are numerically contrast coded.
``` {r inference wrangel}
# prenominal condition is reference level (-1)
d_infer_main_responseCat <- d_infer_main_responseCat %>% mutate(congruence = 
                                                                  ifelse(adj_cond == "incongr", "incongr", "congr"))

# -1 prenominal, 1 predicative
d_infer_main_responseCat <- d_infer_main_responseCat %>% mutate(condition = ifelse(condition == 'predicative', 1, -1),
                                   NP = ifelse(NP == 'subordinate', -1, 1),
                                   congruence = ifelse(congruence == 'congr', -1, 1),
                                   context_cond = ifelse(context_cond == 'sub', -1, 1))
```


The full-size model with maximal random effect structure fails to converge, although the random effect correlation is set to be 0. (probably due to a small data set and many conditions)
```{r inference lmer}
# fails to converge 
#lm.infer.fit <- glmer(response_num ~ condition*NP*congruence*context_cond  + 
#                     (0 + condition*NP*congruence*context_cond|| submission_id) + 
#                        (0 + condition*NP*congruence*context_cond || item), 
#                data = d_infer_main_responseCat, family = "binomial" , REML = F)
# summary(lm.infer.fit)

```
### Congruent trials analysis

Since the main predictions concern the congruent trials, we also analyse congruent trials separately.
The full-scale model with maximal random effect structure fails to converge. 
Given the data, we expect an interaction of the NP and the syntactic condition and a main effect of context, but no interaction of NP, condition and context. We fit a linear model of response predicted by the syntactic condition, the NP, the context and the syntax - NP interaction, with random slope effect of condition and NP interaction by participant. 
This model converges and yield significant results for all predictors (p < 0.01).
``` {r inference lmer 2stats 2-way}
#  congruent trials only
 # full-sized model fails to converge, sequentially  excluding most trivial random effects
d_infer_congr <- d_infer_main_responseCat %>% filter(congruence == -1)
lm.infer.congr <- glmer(response_num ~ condition*NP + context_cond +
                       (0 + condition:NP | submission_id), 
                data = d_infer_congr, family = "binomial" , REML = F)
summary(lm.infer.congr)

```


```{r, echo = FALSE}
# bayesian stats on basic context congruent condition
#brm.infer.congr.basic <- brm(response_num ~ condition*NP,  
                               # (1 | submission_id) +
                              #  (1 | item) +
                              #  (0 + condition| submission_id ) +
                              #  (0 + NP| submission_id) +
                             #   (0 + condition:NP | submission_id) ,
                              #  (0 + condition |item) +
                               # (0 + NP | item) +
                              #  (0 + condition:NP | item),
                       #(0 + condition*NP|| submission_id) + (0 + condition*NP|| item), 
#                data = d_infer_congr_basic) #, family = "binomial" , REML = F)
#summary(lm.infer.congr.basic)
```

### Bayesian Stats
``` {r inference bayes, echo = FALSE}
#contrasts(d_infer_main_responseCat$condition)=matrix(c(-1, 1))
#b.lm.infer.fit <- brm(response_num ~ condition*NP*context_adj + 
 #                      (1|submission_id) + (1 + condition | item), 
  #              data = d_infer_main_responseCat, family = "binomial" )
#summary(b.lm.infer.fit)

```

### Stats including label frequency 
``` {r inference item frequency, echo = FALSE}
item_freqs <- read_csv('./comp-class-inference/data/item_freqs.csv') 
# include the pure basic level category string
d_infer_main_responseCat <- d_infer_main_responseCat %>% rowwise() %>% 
  mutate(basic_cat = ifelse(item == "dogs1", "dogs",
                            ifelse(item == "dogs2", "dogs", item)))
# include the subordinate level category string 
                                                                                         
return_item <- function(condition, context_pic, target_size) {
  if(condition == "incongr") {
    x = sub("images/.*-parade-", "", context_pic)
    x = sub(".png", "", x)
    x = sub("-", " ", x)
  } else if (condition == "congr") {
    x = sub("images/.*-parade-", "", context_pic)
    x = sub(".png", "", x)
    x = sub("-", " ", x)
  } else {
    if (context_pic == "images/bird-parade-basic.png") {
      if (target_size == "small") {
        x=  "hummingbird"
      } else {
        x= "eagle"
      }
    } else if (context_pic == "images/dog-parade-basic.png") {
      if (target_size == "small") {
        x= "chihuahua"
      } else {
        x= "doberman"
      }
    } else if (context_pic == "images/dog-parade-basic2.png") {
      if (target_size == "small") {
        x= "pug"
      } else {
        x= "great dane"
      }
    } else if (context_pic == "images/fish-parade-basic.png") {
      if (target_size == "small") {
        x= "goldfish"
      } else {
        x= "swordfish"
      }
    } else if (context_pic == "images/flower-parade-basic.png") {
      if (target_size == "small") {
        x= "dandelion"
      } else {
        x= "sunflower"
      }
    } else {
      if (target_size == "small") {
        x= "bonsai"
      } else{
        x= "redwood"
      }
    }
  }
  return(x) 
}
items_vec <- Vectorize(return_item, vectorize.args = c("condition", "context_pic", "target_size"))

exp_sub <- items_vec(d_infer_main_responseCat$adj_cond, d_infer_main_responseCat$context_picture, d_infer_main_responseCat$target_size)

d_infer_main_responseCat <- cbind(d_infer_main_responseCat, exp_sub)
d_infer_main_responseCat$sub_freq <- item_freqs$log_sub_log_basic[match(d_infer_main_responseCat$exp_sub, item_freqs$np)]
d_infer_main_responseCat$basic_freq <- log(item_freqs$np_freqs[match(d_infer_main_responseCat$basic_cat, item_freqs$np)])
```

``` {r inference item frequency lmer, echo= FALSE}
# lm with frequency effect

#lm.infer.freq.fit <- glmer(response_num ~ condition*NP*context_cond*congruence + 
 #                            sub_freq +
#                       (1 + condition*NP|| submission_id) + (1 + condition*NP || item), 
 #               data = d_infer_main_responseCat, family = "binomial", REML = F )
#summary(lm.infer.freq.fit)
```